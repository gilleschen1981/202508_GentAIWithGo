# GenAI Foundation Demo

A Go microservice that provides LLM interaction capabilities through gRPC, built with langchain-go.

## Features

- gRPC server with 4 specialized chat interfaces
- LLM integration using langchain-go and VertexAI
- Interactive web frontend with multiple chat modes
- Following the same architecture as the reference project

## Project Structure

```
â”œâ”€â”€ internal.proto          # gRPC interface definition (4 chat interfaces)
â”œâ”€â”€ internal.pb.go          # Generated protobuf code
â”œâ”€â”€ internal_grpc.pb.go     # Generated gRPC code
â”œâ”€â”€ service/                # Service implementation directory
â”‚   â”œâ”€â”€ main.go            # Main entry point and gRPC server
â”‚   â”œâ”€â”€ handler.go         # gRPC handler implementation (4 interfaces)
â”‚   â”œâ”€â”€ service_chat.go    # VertexAI interaction service
â”‚   â”œâ”€â”€ client.go          # VertexAI client wrapper
â”‚   â””â”€â”€ config.go          # Configuration constants
â”œâ”€â”€ pkg/llm/
â”‚   â””â”€â”€ processor.go       # LLM processing abstraction
â”œâ”€â”€ go.mod                 # Go module dependencies
â”œâ”€â”€ run.sh                 # One-click startup script
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html         # Interactive chat UI with 4 modes
â”‚   â””â”€â”€ chat.js            # Frontend JavaScript with mode support
â”œâ”€â”€ QUICKSTART.md          # Quick setup guide
â”œâ”€â”€ CLAUDE.md              # Claude Code development guide
â””â”€â”€ README.md              # This file
```

## Prerequisites

- Go 1.21 or later
- Protocol Buffers compiler (protoc)
- Google Cloud Project with VertexAI enabled
- gcloud CLI installed and authenticated

## Setup

1. **Authenticate with Google Cloud:**
   ```bash
   gcloud auth login
   gcloud auth application-default login
   ```

2. **Set your Google Cloud Project:**
   ```bash
   gcloud config set project YOUR_PROJECT_ID
   ```

3. **Enable VertexAI API:**
   ```bash
   gcloud services enable aiplatform.googleapis.com
   ```

4. **Clone or download the project**

5. **Install dependencies:**
   ```bash
   go mod tidy
   ```

6. **Generate protobuf files (if needed):**
   ```bash
   protoc --go_out=. --go_opt=paths=source_relative --go-grpc_out=. --go-grpc_opt=paths=source_relative internal.proto
   ```

7. **é…ç½® VertexAI å‚æ•°:**

   **æ–¹æ³•ä¸€: ç›´æ¥ä¿®æ”¹ä»£ç ä¸­çš„é…ç½® (æ¨è)**
   ```go
   // ç¼–è¾‘ service/config.go æ–‡ä»¶ï¼Œä¿®æ”¹ä»¥ä¸‹å¸¸é‡:
   const (
       DefaultProjectID = "your-actual-gcp-project-id"  // æ›¿æ¢ä¸ºä½ çš„é¡¹ç›®ID
       DefaultLocation  = "us-central1"                 // å¯é€‰æ‹©å…¶ä»–åŒºåŸŸ
       DefaultModelName = "gemini-1.5-flash"            // å¯é€‰æ‹©å…¶ä»–æ¨¡å‹
   )
   ```

   **æ–¹æ³•äºŒ: ä½¿ç”¨ç¯å¢ƒå˜é‡ (å¯é€‰)**
   ```bash
   export GCP_PROJECT_ID="your-gcp-project-id"
   export VERTEX_AI_LOCATION="us-central1"
   export VERTEX_AI_MODEL="gemini-1.5-flash-001"
   ```

## Running the Service

### å¿«é€Ÿå¯åŠ¨ (æ¨è)
```bash
# ä¸€é”®å¯åŠ¨æœåŠ¡
./run.sh
```

### æ‰‹åŠ¨å¯åŠ¨
```bash
# ç¼–è¯‘å¹¶å¯åŠ¨æœåŠ¡
cd service && go build -o ../genai-service . && cd .. && ./genai-service

# æœåŠ¡å°†åœ¨ 50051 ç«¯å£å¯åŠ¨
```

### æµ‹è¯•æœåŠ¡
```bash
# æ–¹æ³•1: æ‰“å¼€å‰ç«¯é¡µé¢ (æ¨è)
open frontend/index.html

# æ–¹æ³•2: ä½¿ç”¨grpcurlæµ‹è¯•åŸºç¡€æ¥å£
grpcurl -plaintext -d '{"messages":[{"role":"ROLE_USER","content":"Hello!"}]}' localhost:50051 genaidemo.ChatService/Chat

# æ–¹æ³•3: æµ‹è¯•å·¥å…·æ¨¡å¼æ¥å£
grpcurl -plaintext -d '{"messages":[{"role":"ROLE_USER","content":"What is the weather today?"}]}' localhost:50051 genaidemo.ChatService/ChatWithTool
```

## âœ… é¡¹ç›®çŠ¶æ€

- âœ… **4ä¸ªä¸“ä¸šåŒ–èŠå¤©æ¥å£** - Chatã€ChatWithToolã€ChatWithAgentã€ChatWithDoc
- âœ… **çœŸå®VertexAIæ¨¡å¼è¿è¡Œ** - ä½¿ç”¨Gemini-1.5-flashæ¨¡å‹
- âœ… **gRPCæœåŠ¡** - å®Œå…¨åŠŸèƒ½çš„å¾®æœåŠ¡æ¶æ„
- âœ… **å®Œæ•´Tokenç»Ÿè®¡** - çœŸå®çš„è¾“å…¥/è¾“å‡ºtokenè®¡æ•°
- âœ… **å¤šæ¨¡å¼å‰ç«¯ç•Œé¢** - 4ä¸ªæŒ‰é’®å¯¹åº”ä¸åŒèŠå¤©æ¨¡å¼
- âœ… **ä¸€é”®å¯åŠ¨** - ./run.sh è„šæœ¬è‡ªåŠ¨åŒ–æ„å»ºå’Œå¯åŠ¨
- âœ… **æ¨¡å—åŒ–æ¶æ„** - æ¸…æ™°çš„åˆ†å±‚è®¾è®¡å’Œç»„ä»¶åˆ†ç¦»

## API Usage

The service exposes 4 specialized gRPC methods:

```protobuf
service ChatService {
  rpc Chat (ChatRequest) returns (ChatResponse) {}           // Basic chat
  rpc ChatWithTool(ChatRequest) returns (ChatResponse) {}    // Tool-enhanced chat
  rpc ChatWithAgent(ChatRequest) returns (ChatResponse) {}   // Agent-powered chat
  rpc ChatWithDoc(ChatRequest) returns (ChatResponse) {}     // Document-aware chat
}
```

### Interface Descriptions

- **Chat**: Basic LLM conversation interface
- **ChatWithTool**: Enhanced with external tools (web search, calculator, etc.)
- **ChatWithAgent**: Intelligent agent capabilities for complex task coordination
- **ChatWithDoc**: Document analysis and research-oriented responses

### ChatRequest

```protobuf
message ChatRequest {
  repeated Message messages = 1;
  optional float temperature = 2;
  optional int32 max_tokens = 3;
}
```

### ChatResponse

```protobuf
message ChatResponse {
  string content = 1;
  TokenUsage token_usage = 2;
}
```

## Implementation Details

- **service/main.go**: Sets up the gRPC server and initializes the service
- **service/handler.go**: Implements all 4 gRPC interfaces and handles request validation
- **service/service_chat.go**: Contains the actual LLM interaction logic using langchain-go
- **service/client.go**: VertexAI client wrapper with langchain-go integration
- **pkg/llm/processor.go**: LLM processing abstraction layer
- **internal.proto**: Defines 4 specialized gRPC interfaces

## Configuration

The service uses the following environment variables:

- `GCP_PROJECT_ID`: Your Google Cloud Project ID
- `VERTEX_AI_LOCATION`: VertexAI service location (default: us-central1)
- `VERTEX_AI_MODEL`: Model name to use (default: gemini-1.5-flash)

### Available VertexAI Models:
- `gemini-1.5-pro` - Most capable model
- `gemini-1.5-flash` - Fast and efficient (recommended)
- `gemini-1.0-pro` - Stable version

### Available Locations:
- `us-central1`, `us-east1`, `us-west1`
- `europe-west1`, `europe-west4`
- `asia-southeast1`, `asia-northeast1`

The service automatically uses gcloud authentication, so no API keys are needed.

## Frontend

The frontend provides an interactive chat interface with 4 specialized modes:

- **ğŸ”µ Chat**: Basic conversation mode
- **ğŸŸ¢ Tool**: Tool-enhanced responses with search and calculation capabilities  
- **ğŸŸ  Agent**: Intelligent agent mode for complex task coordination
- **ğŸŸ£ Doc**: Document analysis and research mode

Since browsers cannot directly make gRPC calls, the frontend currently simulates different response modes. In a real implementation, you would typically:

1. Create a REST API gateway that translates HTTP to gRPC
2. Use gRPC-Web for direct browser gRPC communication
3. Or use server-sent events for streaming responses

## Testing

You can test the gRPC service using tools like:

- grpcurl
- BloomRPC
- Postman (with gRPC support)

Examples with grpcurl:
```bash
# Test basic Chat
grpcurl -plaintext -d '{"messages":[{"role":"ROLE_USER","content":"Hello!"}]}' localhost:50051 genaidemo.ChatService/Chat

# Test ChatWithTool
grpcurl -plaintext -d '{"messages":[{"role":"ROLE_USER","content":"What is the weather?"}]}' localhost:50051 genaidemo.ChatService/ChatWithTool

# Test ChatWithAgent  
grpcurl -plaintext -d '{"messages":[{"role":"ROLE_USER","content":"Plan a trip to Tokyo"}]}' localhost:50051 genaidemo.ChatService/ChatWithAgent

# Test ChatWithDoc
grpcurl -plaintext -d '{"messages":[{"role":"ROLE_USER","content":"Analyze this document"}]}' localhost:50051 genaidemo.ChatService/ChatWithDoc
```